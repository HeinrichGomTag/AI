{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZZ6YJbwRnQl"
   },
   "source": [
    "# 5-number summary\n",
    "\n",
    "This tutorial is meant to help to load, visualise and analyse datasets in order to prepare them for the data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fKM6j6oKRnQo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#to save the plots to a pdf file\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcgYBy_ldlu6"
   },
   "source": [
    "## General variables configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jI-46v-5RnQp"
   },
   "outputs": [],
   "source": [
    "# dataset name and location\n",
    "dataset_folder = './content/Bristol_owd.csv'\n",
    "\n",
    "# results folder\n",
    "res_folder = './content/'\n",
    "\n",
    "# selecting the features and the time column\n",
    "    # only the features related to the weather that are measurements are selected. That is, features that contains\n",
    "    #  _id, _main, _description, and _icon are removed since they are use by open weather internally\n",
    "    # the city name, lat, lon, and timezone can be safely removed since we have the files separated by city\n",
    "    # we have two times format (dt and dt_iso). We select dt since it is the time in numeric format\n",
    "fetures_to_preserve = ['temp', 'temp_min', 'temp_max', 'feels_like','pressure', 'humidity', 'wind_speed', 'wind_deg',\n",
    "                       'clouds_all', 'Rain_id', 'Rain_main', 'Rain_description']\n",
    "\n",
    "# features to ignore when performing the frequency counts\n",
    "ignore_features = ['temp_min', 'temp_max']\n",
    "\n",
    "######################################## Global variables ########################################\n",
    "# original datasets\n",
    "original_data = None\n",
    "\n",
    "# datasets with the features of interest\n",
    "new_dataset = None\n",
    "\n",
    "# summary of nan values per feature\n",
    "nan_summary = {}\n",
    "\n",
    "# Give format to the features names as appears in the paper proposal\n",
    "formated_features_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlZgycR_dq4K"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MW9cXrtrRnQq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load all the datasets\n",
    "def load_dataset():\n",
    "  global original_data\n",
    "  original_data = pd.read_csv(dataset_folder, sep=\",\", on_bad_lines='skip', dtype='str')\n",
    "\n",
    "\n",
    "# Generate the new dataset\n",
    "def build_new_dataset():\n",
    "  global new_dataset\n",
    "  global original_data\n",
    "  #format the new structure of the data(dataframe)\n",
    "  data_format = pd.DataFrame()\n",
    "  # append the features previously selected (without the time column)\n",
    "  data_format = original_data[fetures_to_preserve]\n",
    "  # append the column time\n",
    "  data_format.index = original_data['dt']\n",
    "  new_dataset = data_format\n",
    "\n",
    "# Compute a summary for all nan values per feature per dataset\n",
    "def compute_nan_summary(dataset):\n",
    "  global nan_summary\n",
    "  print('Computing Nan summary')\n",
    "  summary = {}\n",
    "  for feature in list(dataset.columns):\n",
    "      na_total = dataset[feature].isnull().sum()\n",
    "      na_percentage = (na_total*100)/len(dataset.index)\n",
    "\n",
    "      summary[feature] = [na_total, na_percentage]\n",
    "\n",
    "  nan_summary = pd.DataFrame(summary, columns = list(dataset.columns), index = ['Na No', 'Na %'])\n",
    "\n",
    "# Write the nan summary resutls as a Excel file\n",
    "def write_nan_summary():\n",
    "  with pd.ExcelWriter(res_folder + 'Nan_summary.xlsx') as writer:\n",
    "    nan_summary.to_excel(writer, sheet_name='values')\n",
    "\n",
    "# Plot the behaviour of the features across time\n",
    "def plot_feats_across_time(dataset):\n",
    "  print('Ploting features behaviour')\n",
    "\n",
    "  #transform each column type of the dataset to numeric(float) to perform the analysis\n",
    "  dataset = dataset.iloc[:,:-3]\n",
    "  dataset = dataset.astype(float)\n",
    "\n",
    "  plots_output = res_folder + 'features_across_time.pdf'\n",
    "  #taking a look of the features variation across time\n",
    "  plt.rcParams[\"figure.figsize\"] = (20,30)\n",
    "  dataset.plot(subplots=True)\n",
    "  plt.savefig(plots_output)\n",
    "  plt.close('all')\n",
    "\n",
    "# Compute the 5-number summary\n",
    "def five_number_summary(dataset):\n",
    "  print('Computing the 5-number summary')\n",
    "\n",
    "  #transform each column type of the dataset to numeric(float) to perform the analysis\n",
    "  dataset = dataset.iloc[:,:-3]\n",
    "  dataset = dataset.astype(float)\n",
    "\n",
    "  with pd.ExcelWriter(res_folder + '5_number_summary.xlsx') as writer:\n",
    "    #minimum\n",
    "    dataset_min = dataset.min()\n",
    "    #lower quartile\n",
    "    dataset_lq = dataset.quantile(.25, axis = 0)\n",
    "    #median\n",
    "    dataset_med = dataset.median()\n",
    "    #uper quartile\n",
    "    dataset_uq = dataset.quantile(.75, axis = 0)\n",
    "    #maximum\n",
    "    dataset_max = dataset.max()\n",
    "\n",
    "    summary = pd.concat([dataset_min.rename(\"Min\"), \n",
    "                    dataset_lq.rename(\"Lower quartile\"),\n",
    "                    dataset_med.rename(\"Median\"),\n",
    "                    dataset_uq.rename(\"Uper quartile\"),\n",
    "                    dataset_max.rename(\"Max\")], axis=1)\n",
    "\n",
    "    summary.to_excel(writer, sheet_name='values')\n",
    "\n",
    "# Plot boxplots and histograms per feature\n",
    "def plot_boxplots_histograms(dataset):\n",
    "  print('Ploting boxplots and histograms')\n",
    "  #transform each column type of the dataset to numeric(float) to perform the analysis\n",
    "  dataset = dataset.iloc[:,:-3]\n",
    "  dataset = dataset.astype(float)\n",
    "\n",
    "  plots_output = res_folder + 'box_plots_&_histograms.pdf'\n",
    "  pdf = PdfPages(plots_output)\n",
    "\n",
    "  plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "  for feature in list(dataset.columns):\n",
    "      fig, axes = plt.subplots(1, 2)\n",
    "      dataset.boxplot(column=feature, ax=axes[0])\n",
    "      dataset.hist(column=feature, ax=axes[1])\n",
    "      pdf.savefig(fig)\n",
    "\n",
    "  pdf.close()\n",
    "  plt.close('all')\n",
    "\n",
    "# Plot all histograms of all features per dataset together\n",
    "def plot_histograms(dataset):\n",
    "  print('Ploting histograms')\n",
    "  #transform each column type of the dataset to numeric(float) to perform the analysis\n",
    "  dataset = dataset.iloc[:,:-3]\n",
    "  dataset = dataset.astype(float)\n",
    "\n",
    "  plots_output = res_folder + 'all_histograms.pdf'\n",
    "  plt.rcParams[\"figure.figsize\"] = (20,15)\n",
    "  dataset.hist()\n",
    "  plt.savefig(plots_output)\n",
    "  plt.close('all')\n",
    "\n",
    "# Compute the frequency counts per feature per dataset\n",
    "# Compute the frequency counts per feature per dataset\n",
    "def freq_counts(dataset):\n",
    "    print('Computing frequency counts')\n",
    "\n",
    "    with pd.ExcelWriter(res_folder + 'frequency_counts.xlsx') as writer:\n",
    "        # Create a visible sheet with the first row of the dataset\n",
    "        dataset.iloc[:1].to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "        # Transform each column type of the dataset to numeric (float) to perform the analysis\n",
    "        dataset = dataset.iloc[:, :-3].astype(float)\n",
    "\n",
    "        for feature in list(dataset.columns):\n",
    "            if feature not in ignore_features:\n",
    "                min_val = dataset[feature].min()\n",
    "                max_val = dataset[feature].max()\n",
    "\n",
    "                if isinstance(min_val, float):\n",
    "                    min_val = np.round(min_val, 0).astype(int)\n",
    "\n",
    "                if isinstance(max_val, float):\n",
    "                    max_val = np.round(max_val, 0).astype(int)\n",
    "\n",
    "                ranges = []\n",
    "                for i in range(min_val, max_val + 2):\n",
    "                    ranges.append(i)\n",
    "\n",
    "                temp_feat_df = dataset[feature]\n",
    "                counts = temp_feat_df.groupby(pd.cut(temp_feat_df, ranges)).count()\n",
    "\n",
    "                counts.to_excel(writer, sheet_name=feature)\n",
    "\n",
    "# Generate all the analysis plots\n",
    "def analysis_plots(dataset):\n",
    "    # revise for NaN values\n",
    "    compute_nan_summary(dataset)\n",
    "    \n",
    "    # write nan summary results for each dataset/city\n",
    "    write_nan_summary()\n",
    "    \n",
    "    # generate the plots to see features behaviour across time\n",
    "    plot_feats_across_time(dataset)\n",
    "    \n",
    "    # generate the 5-number summary\n",
    "    five_number_summary(dataset)\n",
    "\n",
    "    # plot the boxplots and histograms\n",
    "    plot_boxplots_histograms(dataset)\n",
    "\n",
    "    # plot the histograms together\n",
    "    plot_histograms(dataset)\n",
    "    \n",
    "    # compute the frequency counts\n",
    "    freq_counts(dataset)\n",
    "\n",
    "# Plot nullness/nans percentages of the features in a dataset\n",
    "def plot_nullness():\n",
    "  global nan_summary\n",
    "\n",
    "  plt.rcParams['axes.labelsize'] = 13\n",
    "  plt.rcParams['axes.labelweight'] = 'bold'\n",
    "  \n",
    "  plots_output = res_folder + 'nullness.pdf'\n",
    "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(15,25), dpi= 80)\n",
    "  fig.subplots_adjust(hspace=.07, wspace=.05)\n",
    "  \n",
    "  ax.scatter(y=nan_summary.columns, x=nan_summary.iloc[1,:], color='purple', alpha=1)\n",
    "  ax.set_xlabel('Nullness %')\n",
    "  ax.set_yticks(nan_summary.columns)\n",
    "  ax.set_yticklabels(nan_summary.columns, fontdict={'horizontalalignment': 'right'}, size = 13, weight = 'bold' )\n",
    "  ax.set_xlim(-5, 105)\n",
    "  ax.grid(True)\n",
    "  ax.set_axisbelow(True)\n",
    "  ax.set_title('Bristol', size = 16, weight = 'bold')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  fig.savefig(plots_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbqlDSD6dzN6"
   },
   "source": [
    "## Load the dataset and visualise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luF43vZ_RnQs",
    "outputId": "5dac361c-9cf1-4c14-d201-0c2a78a65dcd"
   },
   "outputs": [],
   "source": [
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "WsREhW0DRnQs",
    "outputId": "41ecf8b8-db5c-4052-9359-1919d4967b6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>...</th>\n",
       "      <th>Dust_description</th>\n",
       "      <th>Dust_icon</th>\n",
       "      <th>Tornado_id</th>\n",
       "      <th>Tornado_main</th>\n",
       "      <th>Tornado_description</th>\n",
       "      <th>Tornado_icon</th>\n",
       "      <th>Squall_id</th>\n",
       "      <th>Squall_main</th>\n",
       "      <th>Squall_description</th>\n",
       "      <th>Squall_icon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.454513</td>\n",
       "      <td>-2.58791</td>\n",
       "      <td>47.95</td>\n",
       "      <td>46.4</td>\n",
       "      <td>49.82</td>\n",
       "      <td>45.07</td>\n",
       "      <td>1020</td>\n",
       "      <td>92</td>\n",
       "      <td>3.36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.454513</td>\n",
       "      <td>-2.58791</td>\n",
       "      <td>48.09</td>\n",
       "      <td>46.22</td>\n",
       "      <td>50</td>\n",
       "      <td>43.56</td>\n",
       "      <td>1021</td>\n",
       "      <td>97</td>\n",
       "      <td>6.93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.454513</td>\n",
       "      <td>-2.58791</td>\n",
       "      <td>48.15</td>\n",
       "      <td>46.04</td>\n",
       "      <td>49.82</td>\n",
       "      <td>44.19</td>\n",
       "      <td>1021</td>\n",
       "      <td>96</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.454513</td>\n",
       "      <td>-2.58791</td>\n",
       "      <td>48.18</td>\n",
       "      <td>46.22</td>\n",
       "      <td>49.82</td>\n",
       "      <td>43.61</td>\n",
       "      <td>1021</td>\n",
       "      <td>96</td>\n",
       "      <td>6.93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.454513</td>\n",
       "      <td>-2.58791</td>\n",
       "      <td>47.64</td>\n",
       "      <td>45.89</td>\n",
       "      <td>49.28</td>\n",
       "      <td>45.01</td>\n",
       "      <td>1022</td>\n",
       "      <td>97</td>\n",
       "      <td>3.36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_name        lat       lon   temp temp_min temp_max feels_like pressure  \\\n",
       "0   Bristol  51.454513  -2.58791  47.95     46.4    49.82      45.07     1020   \n",
       "1   Bristol  51.454513  -2.58791  48.09    46.22       50      43.56     1021   \n",
       "2   Bristol  51.454513  -2.58791  48.15    46.04    49.82      44.19     1021   \n",
       "3   Bristol  51.454513  -2.58791  48.18    46.22    49.82      43.61     1021   \n",
       "4   Bristol  51.454513  -2.58791  47.64    45.89    49.28      45.01     1022   \n",
       "\n",
       "  humidity wind_speed  ... Dust_description Dust_icon Tornado_id Tornado_main  \\\n",
       "0       92       3.36  ...              NaN       NaN        NaN          NaN   \n",
       "1       97       6.93  ...              NaN       NaN        NaN          NaN   \n",
       "2       96       5.82  ...              NaN       NaN        NaN          NaN   \n",
       "3       96       6.93  ...              NaN       NaN        NaN          NaN   \n",
       "4       97       3.36  ...              NaN       NaN        NaN          NaN   \n",
       "\n",
       "  Tornado_description Tornado_icon Squall_id Squall_main Squall_description  \\\n",
       "0                 NaN          NaN       NaN         NaN                NaN   \n",
       "1                 NaN          NaN       NaN         NaN                NaN   \n",
       "2                 NaN          NaN       NaN         NaN                NaN   \n",
       "3                 NaN          NaN       NaN         NaN                NaN   \n",
       "4                 NaN          NaN       NaN         NaN                NaN   \n",
       "\n",
       "  Squall_icon  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a quick view of Bristol data\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BB6UnIVcUtz",
    "outputId": "8c00a215-a030-477c-ec68-5f507b3f9ec9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2000-01-01 00:00:00 +0000 UTC\n",
       "1         2000-01-01 01:00:00 +0000 UTC\n",
       "2         2000-01-01 02:00:00 +0000 UTC\n",
       "3         2000-01-01 03:00:00 +0000 UTC\n",
       "4         2000-01-01 04:00:00 +0000 UTC\n",
       "                      ...              \n",
       "178003    2020-04-21 19:00:00 +0000 UTC\n",
       "178004    2020-04-21 20:00:00 +0000 UTC\n",
       "178005    2020-04-21 21:00:00 +0000 UTC\n",
       "178006    2020-04-21 22:00:00 +0000 UTC\n",
       "178007    2020-04-21 23:00:00 +0000 UTC\n",
       "Name: dt_iso, Length: 178008, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data['dt_iso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPd1_0YuRnQt",
    "outputId": "f2f3a4dd-fc4f-4fb2-82fa-2b3b9c015c6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_name', 'lat', 'lon', 'temp', 'temp_min', 'temp_max', 'feels_like',\n",
       "       'pressure', 'humidity', 'wind_speed', 'wind_deg', 'clouds_all', 'dt',\n",
       "       'dt_iso', 'timezone', 'Rain_id', 'Rain_main', 'Rain_description',\n",
       "       'Rain_icon', 'Drizzle_id', 'Drizzle_main', 'Drizzle_description',\n",
       "       'Drizzle_icon', 'Fog_id', 'Fog_main', 'Fog_description', 'Fog_icon',\n",
       "       'Clouds_id', 'Clouds_main', 'Clouds_description', 'Clouds_icon',\n",
       "       'Haze_id', 'Haze_main', 'Haze_description', 'Haze_icon', 'Mist_id',\n",
       "       'Mist_main', 'Mist_description', 'Mist_icon', 'Clear_id', 'Clear_main',\n",
       "       'Clear_description', 'Clear_icon', 'Snow_id', 'Snow_main',\n",
       "       'Snow_description', 'Snow_icon', 'Thunderstorm_id', 'Thunderstorm_main',\n",
       "       'Thunderstorm_description', 'Thunderstorm_icon', 'Smoke_id',\n",
       "       'Smoke_main', 'Smoke_description', 'Smoke_icon', 'Dust_id', 'Dust_main',\n",
       "       'Dust_description', 'Dust_icon', 'Tornado_id', 'Tornado_main',\n",
       "       'Tornado_description', 'Tornado_icon', 'Squall_id', 'Squall_main',\n",
       "       'Squall_description', 'Squall_icon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the name of the columns\n",
    "original_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKFtLzrIfQXl"
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "dmp6ZQD0RnQu"
   },
   "outputs": [],
   "source": [
    "# Generate the new dataset\n",
    "build_new_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "R-YV9NyqRnQu",
    "outputId": "bfab2234-0433-4531-de74-5027171525e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>Rain_id</th>\n",
       "      <th>Rain_main</th>\n",
       "      <th>Rain_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946684800</th>\n",
       "      <td>47.95</td>\n",
       "      <td>46.4</td>\n",
       "      <td>49.82</td>\n",
       "      <td>45.07</td>\n",
       "      <td>1020</td>\n",
       "      <td>92</td>\n",
       "      <td>3.36</td>\n",
       "      <td>230</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946688400</th>\n",
       "      <td>48.09</td>\n",
       "      <td>46.22</td>\n",
       "      <td>50</td>\n",
       "      <td>43.56</td>\n",
       "      <td>1021</td>\n",
       "      <td>97</td>\n",
       "      <td>6.93</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946692000</th>\n",
       "      <td>48.15</td>\n",
       "      <td>46.04</td>\n",
       "      <td>49.82</td>\n",
       "      <td>44.19</td>\n",
       "      <td>1021</td>\n",
       "      <td>96</td>\n",
       "      <td>5.82</td>\n",
       "      <td>240</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946695600</th>\n",
       "      <td>48.18</td>\n",
       "      <td>46.22</td>\n",
       "      <td>49.82</td>\n",
       "      <td>43.61</td>\n",
       "      <td>1021</td>\n",
       "      <td>96</td>\n",
       "      <td>6.93</td>\n",
       "      <td>240</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946699200</th>\n",
       "      <td>47.64</td>\n",
       "      <td>45.89</td>\n",
       "      <td>49.28</td>\n",
       "      <td>45.01</td>\n",
       "      <td>1022</td>\n",
       "      <td>97</td>\n",
       "      <td>3.36</td>\n",
       "      <td>270</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temp temp_min temp_max feels_like pressure humidity wind_speed  \\\n",
       "dt                                                                           \n",
       "946684800  47.95     46.4    49.82      45.07     1020       92       3.36   \n",
       "946688400  48.09    46.22       50      43.56     1021       97       6.93   \n",
       "946692000  48.15    46.04    49.82      44.19     1021       96       5.82   \n",
       "946695600  48.18    46.22    49.82      43.61     1021       96       6.93   \n",
       "946699200  47.64    45.89    49.28      45.01     1022       97       3.36   \n",
       "\n",
       "          wind_deg clouds_all Rain_id Rain_main Rain_description  \n",
       "dt                                                                \n",
       "946684800      230         40     NaN       NaN              NaN  \n",
       "946688400      250         20     NaN       NaN              NaN  \n",
       "946692000      240         40     NaN       NaN              NaN  \n",
       "946695600      240         40     NaN       NaN              NaN  \n",
       "946699200      270         40     NaN       NaN              NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the dataset processed\n",
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ar7DbfGLRnQv",
    "outputId": "e7cbb78e-2918-473b-ed29-35b0568e6447",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Nan summary\n",
      "Ploting features behaviour\n",
      "Computing the 5-number summary\n",
      "Ploting boxplots and histograms\n",
      "Ploting histograms\n",
      "Computing frequency counts\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Perform all the analysis\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manalysis_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 165\u001b[0m, in \u001b[0;36manalysis_plots\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    162\u001b[0m plot_histograms(dataset)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# compute the frequency counts\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[43mfreq_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 131\u001b[0m, in \u001b[0;36mfreq_counts\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    128\u001b[0m max_val \u001b[38;5;241m=\u001b[39m dataset[feature]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(min_val, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 131\u001b[0m     min_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmin_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(max_val, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    134\u001b[0m     max_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(max_val, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# Perform all the analysis\n",
    "analysis_plots(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b6ekYUvgRnQv",
    "outputId": "9e7acfae-8190-4f4f-edc6-cce428e2ac67"
   },
   "outputs": [],
   "source": [
    "# Plot features nullness(nans)\n",
    "plot_nullness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Replace missing values with the average (mean) of the respective column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Rain_id'] = df['Rain_id'].fillna(df['Rain_id'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For categorical columns, you might want to use the mode (the most frequent value) instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Rain_main'] = df['Rain_main'].fillna(df['Rain_main'].mode()[0])\n",
    "# df['Rain_description'] = df['Rain_description'].fillna(df['Rain_description'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Replace missing values with the nearest non-null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Rain_id'] = df['Rain_id'].fillna(method='ffill')\n",
    "# df['Rain_main'] = df['Rain_main'].fillna(method='ffill')\n",
    "# df['Rain_description'] = df['Rain_description'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Remove all rows that contain at least one NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=['Rain_id', 'Rain_main', 'Rain_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can call the analysis_plots function for each approach and draw conclusions based on the results.\n",
    "\n",
    "As for the conclusion, it will depend on the results you get from the analysis_plots function and your specific use case. Generally, if the data is not missing at random, it might be better to use an approach like filling with the mean or mode or forward filling. If the data is missing randomly and the percentage of missing data is small, you may opt for dropping the rows with missing values.\n",
    "\n",
    "Remember to make a copy of your DataFrame before applying each approach, so you can compare the results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original DataFrame\n",
    "df_copy1 = df.copy()\n",
    "\n",
    "# 1. Replace missing values with the average (mean) of the respective column\n",
    "df_copy1['Rain_id'] = df_copy1['Rain_id'].fillna(df_copy1['Rain_id'].mean())\n",
    "df_copy1['Rain_main'] = df_copy1['Rain_main'].fillna(df_copy1['Rain_main'].mode()[0])\n",
    "df_copy1['Rain_description'] = df_copy1['Rain_description'].fillna(df_copy1['Rain_description'].mode()[0])\n",
    "\n",
    "# Call the analysis_plots function and draw conclusions based on the results\n",
    "# analysis_plots(df_copy1)\n",
    "analysis_plots(df_copy1)\n",
    "\n",
    "# Make a copy of the original DataFrame\n",
    "df_copy2 = df.copy()\n",
    "\n",
    "# 2. Replace missing values with the nearest non-null value\n",
    "df_copy2['Rain_id'] = df_copy2['Rain_id'].fillna(method='ffill')\n",
    "df_copy2['Rain_main'] = df_copy2['Rain_main'].fillna(method='ffill')\n",
    "df_copy2['Rain_description'] = df_copy2['Rain_description'].fillna(method='ffill')\n",
    "\n",
    "# Call the analysis_plots function and draw conclusions based on the results\n",
    "# analysis_plots(df_copy2)\n",
    "analysis_plots(df_copy2)\n",
    "\n",
    "# Make a copy of the original DataFrame\n",
    "df_copy3 = df.copy()\n",
    "\n",
    "# 3. Remove all rows that contain at least one NaN value\n",
    "df_copy3 = df_copy3.dropna(subset=['Rain_id', 'Rain_main', 'Rain_description'])\n",
    "\n",
    "# Call the analysis_plots function and draw conclusions based on the results\n",
    "# analysis_plots(df_copy3)\n",
    "analysis_plots(df_copy3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
